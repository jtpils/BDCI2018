{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from datetime import datetime\n",
    "import os.path\n",
    "import sys\n",
    "import time\n",
    "import glob\n",
    "import numpy as np\n",
    "from six.moves import xrange\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from config import *\n",
    "from imdb import  kitti\n",
    "from utils.util import *\n",
    "from nets import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "path = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "FLAGS = tf.app.flags.FLAGS\n",
    "\n",
    "tf.app.flags.DEFINE_string(\n",
    "        'checkpoint', path[:-4]+'/data/best/model.ckpt-49999',\n",
    "        \"\"\"Path to the model parameter file.\"\"\")\n",
    "tf.app.flags.DEFINE_string(\n",
    "        'input_path', path[:-4]+'/data/samples/*',\n",
    "        \"\"\"Input lidar scan to be detected. Can process glob input such as \"\"\"\n",
    "        \"\"\"./data/samples/*.npy or single input.\"\"\")\n",
    "tf.app.flags.DEFINE_string(\n",
    "        'out_dir', path[:-4]+'/data/samples_out/', \"\"\"Directory to dump output.\"\"\")\n",
    "tf.app.flags.DEFINE_string('gpu', '0', \"\"\"gpu id.\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rospy\n",
    "import std_msgs.msg\n",
    "import sensor_msgs.point_cloud2 as pc2\n",
    "from sensor_msgs.msg import PointCloud2\n",
    "from visualization_msgs.msg import Marker\n",
    "from geometry_msgs.msg import Point\n",
    "\n",
    "def publish_pc(pc,car,person,cyc):\n",
    "    pub = rospy.Publisher('/points_raw',PointCloud2,queue_size=10000)\n",
    "    rospy.init_node('velo_publisher')\n",
    "    header = std_msgs.msg.Header()\n",
    "    header.stamp = rospy.Time.now()\n",
    "    header.frame_id = 'velody'\n",
    "    points = pc2.create_cloud_xyz32(header,pc)\n",
    "    '''\n",
    "    pub2 = rospy.Publisher('/point_seg',PointCloud2,queue_size=10000)\n",
    "    header = std_msgs.msg.Header()\n",
    "    header.stamp = rospy.Time.now()\n",
    "    header.frame_id = 'velody'\n",
    "    points2 = pc2.create_cloud_xyz32(header,obj)\n",
    "    '''\n",
    "    pub_car =rospy.Publisher(\"/points_raw1\",Marker,queue_size=100000)\n",
    "    marker_car =print_car(pub_car,car)\n",
    "    \n",
    "    pub_per =rospy.Publisher(\"/points_raw2\",Marker,queue_size=100000)\n",
    "    marker_per =print_person(pub_per,person)\n",
    "    \n",
    "    pub_cyc=rospy.Publisher(\"/points_raw3\",Marker,queue_size=100000)\n",
    "    marker_cyc =print_cyc(pub_cyc,cyc)\n",
    "    \n",
    "    \n",
    "    \n",
    "    r = rospy.Rate(0.1)\n",
    "    while not rospy.is_shutdown():\n",
    "        pub.publish(points)\n",
    "        pub_car.publish(marker_car)\n",
    "        pub_per.publish(marker_per)\n",
    "        pub_cyc.publish(marker_cyc)\n",
    "        r.sleep()\n",
    "        \n",
    "def print_car(pub,points):\n",
    "    triplePoints=[]\n",
    "    for (x,y,z) in points:\n",
    "        p = Point()\n",
    "        p.x = x\n",
    "        p.y = y\n",
    "        p.z = z\n",
    "        triplePoints.append(p)\n",
    "    marker = Marker()\n",
    "    marker.header.frame_id = 'velody'\n",
    "    marker.type = marker.POINTS\n",
    "    marker.action = marker.ADD\n",
    "    marker.pose.orientation.w = 1\n",
    "    marker.points = triplePoints\n",
    "\n",
    "    marker.scale.x = 0.05\n",
    "    marker.scale.y = 0.05\n",
    "    marker.scale.z = 0.05\n",
    "    marker.color.a = 1.0\n",
    "    marker.color.r = 1.0\n",
    "    return marker\n",
    "\n",
    "def print_person(pub,points):\n",
    "    triplePoints=[]\n",
    "    for (x,y,z) in points:\n",
    "        p = Point()\n",
    "        p.x = x\n",
    "        p.y = y\n",
    "        p.z = z\n",
    "        triplePoints.append(p)\n",
    "    marker = Marker()\n",
    "    marker.header.frame_id = 'velody'\n",
    "    marker.type = marker.POINTS\n",
    "    marker.action = marker.ADD\n",
    "    marker.pose.orientation.w = 1\n",
    "    marker.points = triplePoints\n",
    "\n",
    "    marker.scale.x = 0.05\n",
    "    marker.scale.y = 0.05\n",
    "    marker.scale.z = 0.05\n",
    "    marker.color.a = 1.0\n",
    "    marker.color.g = 1.0\n",
    "    return marker\n",
    "\n",
    "def print_cyc(pub,points):\n",
    "    triplePoints=[]\n",
    "    for (x,y,z) in points:\n",
    "        p = Point()\n",
    "        p.x = x\n",
    "        p.y = y\n",
    "        p.z = z\n",
    "        triplePoints.append(p)\n",
    "    marker = Marker()\n",
    "    marker.header.frame_id = 'velody'\n",
    "    marker.type = marker.POINTS\n",
    "    marker.action = marker.ADD\n",
    "    marker.pose.orientation.w = 1\n",
    "    marker.points = triplePoints\n",
    "\n",
    "    marker.scale.x = 0.05\n",
    "    marker.scale.y = 0.05\n",
    "    marker.scale.z = 0.05\n",
    "    marker.color.a = 1.0\n",
    "    marker.color.b = 1.0\n",
    "    return marker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_seg(label_map, mc, one_hot=False):\n",
    "  if one_hot:\n",
    "    label_map = np.argmax(label_map, axis=-1)\n",
    "  out = np.zeros(\n",
    "      (label_map.shape[0], label_map.shape[1], label_map.shape[2], 3))\n",
    "\n",
    "  for l in range(1, mc.NUM_CLASS):\n",
    "    out[label_map==l, :] = mc.CLS_COLOR_MAP[l]\n",
    "\n",
    "  return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _normalize(x):\n",
    "  return (x - x.min())/(x.max() - x.min())\n",
    "\n",
    "def detect():\n",
    "  \"\"\"Detect LiDAR data.\"\"\"\n",
    "\n",
    "  os.environ['CUDA_VISIBLE_DEVICES'] = FLAGS.gpu\n",
    "\n",
    "  with tf.Graph().as_default():\n",
    "    mc = kitti_squeezeSeg_config()\n",
    "    mc.LOAD_PRETRAINED_MODEL = False\n",
    "    mc.BATCH_SIZE = 1 # TODO(bichen): fix this hard-coded batch size.\n",
    "    model = SqueezeSeg(mc)\n",
    "\n",
    "    saver = tf.train.Saver(model.model_params)\n",
    "    with tf.Session(config=tf.ConfigProto(allow_soft_placement=True)) as sess:\n",
    "      saver.restore(sess, FLAGS.checkpoint)\n",
    "      for f in glob.iglob(FLAGS.input_path):\n",
    "        lidar = np.load(f).astype(np.float32, copy=False)[:, :, :5]\n",
    "        lidar_mask = np.reshape(\n",
    "            (lidar[:, :, 4] > 0),\n",
    "            [mc.ZENITH_LEVEL, mc.AZIMUTH_LEVEL, 1]\n",
    "        )\n",
    "        lidar_nor = (lidar - mc.INPUT_MEAN)/mc.INPUT_STD\n",
    "\n",
    "        pred_cls = sess.run(\n",
    "            model.pred_cls,\n",
    "            feed_dict={\n",
    "                model.lidar_input:[lidar_nor],\n",
    "                model.keep_prob: 1.0,\n",
    "                model.lidar_mask:[lidar_mask]\n",
    "            }\n",
    "        )\n",
    "        # save the data\n",
    "        #print(pred_cls[0].shape)\n",
    "        #plt.imshow(pred_cls[0])\n",
    "        \n",
    "        lidar_xyz = lidar[:,:,:3]\n",
    "        #print(lidar_xyz.shape)\n",
    "        lidar_raw = lidar_xyz.reshape(-1,3)\n",
    "        print (lidar_raw.shape)\n",
    "        \n",
    "        Mask = pred_cls[0].reshape(-1,1)\n",
    "        print(Mask[:,0].shape)\n",
    "        start =time.time()\n",
    "        id_0 = np.argwhere(Mask[:,0]==1)\n",
    "        id_1 = np.argwhere(Mask[:,0]==2)\n",
    "        id_2 = np.argwhere(Mask[:,0]==3)\n",
    "        \n",
    "        car= []\n",
    "        for index in id_0:\n",
    "            car.append(lidar_raw[index,:])\n",
    "        car = np.array(car)\n",
    "        car = car.reshape(-1,3)\n",
    "        \n",
    "        pedestrian=[]\n",
    "        for index in id_1:\n",
    "            pedestrian.append(lidar_raw[index,:])\n",
    "        pedestrian = np.array(pedestrian)\n",
    "        pedestrian = pedestrian.reshape(-1,3)\n",
    "        \n",
    "        cyc=[]\n",
    "        for index in id_2:\n",
    "            cyc.append(lidar_raw[index,:])\n",
    "        cyc = np.array(cyc)\n",
    "        cyc = cyc.reshape(-1,3)\n",
    "        \n",
    "        \n",
    "        publish_pc(lidar_raw,car,pedestrian,cyc)\n",
    "        \n",
    "        \n",
    "        print(time.time()-start)\n",
    "        '''\n",
    "        file_name = f.strip('.npy').split('/')[-1]\n",
    "        np.save(\n",
    "            os.path.join(FLAGS.out_dir, 'pred_'+file_name+'.npy'),\n",
    "            pred_cls[0]\n",
    "        )\n",
    "\n",
    "        # save the plot\n",
    "        depth_map = Image.fromarray(\n",
    "            (255 * _normalize(lidar[:, :, 3])).astype(np.uint8))\n",
    "        label_map = Image.fromarray(\n",
    "            (255 * visualize_seg(pred_cls, mc)[0]).astype(np.uint8))\n",
    "\n",
    "        blend_map = Image.blend(\n",
    "            depth_map.convert('RGBA'),\n",
    "            label_map.convert('RGBA'),\n",
    "            alpha=0.4\n",
    "        )\n",
    "\n",
    "        blend_map.save(\n",
    "            os.path.join(FLAGS.out_dir, 'plot_'+file_name+'.png'))\n",
    "        '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(argv=None):\n",
    "  if not tf.gfile.Exists(FLAGS.out_dir):\n",
    "    tf.gfile.MakeDirs(FLAGS.out_dir)\n",
    "  detect()\n",
    "  print('Detection output written to {}'.format(FLAGS.out_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From nn_skeleton.py:1159: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From nn_skeleton.py:127: calling softmax (from tensorflow.python.ops.nn_ops) with dim is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "dim is deprecated, use axis instead\n",
      "------- []\n",
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/clip_ops.py:110: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "INFO:tensorflow:Restoring parameters from /usr/app/code/wk_sp_3/LKN_seg/data/best/model.ckpt-49999\n",
      "(32768, 3)\n",
      "(32768,)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    tf.app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
